---
output: 
  pdf_document:
    keep_tex: true
    fig_caption: true
    latex_engine: pdflatex
    template: ./svm-latex-ms.tex
    toc: true
    toc_depth: 2
    number_sections: true
title: "Predicting Admission Probability in U.S Grad school using Linear Models and Machine Learning Algorithms"
thanks: "S.V Miller for providing the Pandoc template: github.com/svmiller"
author:
- name: Arumugam Thiagarajan
  affiliation: Professional Certificate in Data Science, Harvard University
abstract: "The project develops and compares a linear and a suite of machine learning algorithms that predicts the admission probabilty of applicants to United States Graduate Schools. The applicant characterisitics and academic standings such as, TOEFL scores, GRE scores, Cumulative Grade Point Average (CGPA), Letter of Recommendation (LOR) and Statement of Purpose are some of the attributes that are used to predict their admission probability to universities. A regression based approach was used and the dataset was explored for trends, cleansed with relevant attributes and models were built using linear regression and machine learning algorithm. Training and validation datasets were estbalished at a 50:50 proportion at random. Root Mean Square and R2 values were used as measures of performance and the results revealed that linear regression model and an ensemble of machine learning models both predicted the outcomes with the same level of accuracy. The RMSE values were at 0.066 with an r2 value of 0.88"

keywords: "house rent, machine learning, linear models"
date: "`r format(Sys.time(), '%B %d, %Y')`"
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
# spacing: double
#bibliography: ~/houserent.bib
#biblio-style: apsr
---


# Executive Summary

This project builds a mathematical model that predicts the house rents in selected Brazilian cities. 


# Objective
Predict the admission rates in United States Grad School using the academic scores of the applicants, and the university rankings. Both general linear models and machine learning algorithms will be used and their performances will be compared. Root Mean Squarewill be used as the measure of performance for the model.  


#Install and load up the libraries that are required for the analysis to run.
```{r echo=F, inlcude=F, message=F}
needed.packages <- c("tidyverse", "caret", "knitr", "MASS",
                     "ppcor" , "doParallel", "ggthemes", 
                     "corrplot", "glmnet", "car", "Rborist",
                     "caretEnsemble", "PerformanceAnalytics", 
                     "DataExplorer", "forecast", "kableExtra")

new.packages <- needed.packages[!(needed.packages %in% installed.packages()[,"Package"])]

if(length(new.packages)) 
  install.packages(new.packages)


library(tidyverse)
library(MASS)
library(forecast)
library(caretEnsemble)
library(caret)
library(DataExplorer)
library(ppcor)
library(doParallel)
library(ggthemes)
library(corrplot)
library(glmnet)
library(car)
library(Rborist)
library(kableExtra)
library(PerformanceAnalytics)
```

# Load the data that is used for the development of the model.

The original data is available for public in the following url: https://www.kaggle.com/

Since a direct download from kaggle requires an authentication, the whole dataset is uploaded to github account. The data and codes can be downloaded from the following github repository. 
https://github.com/HexyCodes/ 

This dataset contains, 400 rows of data and 8 attributes. 

#Data characteristics and Summary
```{r}
adm=read.csv("~/Documents/Harvard/R/CapStone/Admission/US_grad_admission.csv", 
             stringsAsFactors = F)
dim(adm) # find the dimensions of the data.frame
```


# Exploratory Data Analysis

Here the data is analyzed for their summarized characteristics through visualization. This step allows us to find the patterns, trends and any anamolies if exist in the data. The serial number column has been removed to cleanse the data removing unrelated column. This was an obvious choice as this will add unncessary noise to the modeling process.
```{r}
class(adm)
head(adm,5) # look at the data type of columns
print(anyNA(adm))# check for missing values
summary(adm) # quantile distribution of the predicted values
adm%>%ggplot(aes(x=Chance.of.Admit))+geom_density(bins = 20, fill="blue") + theme_bw() 

  # distribution 
#pattern of the predicted value
qqnorm(adm$Chance.of.Admit)
 
 
adm%>%dplyr::select(-Serial.No.)->adm # Remove Serial number from the daa. 
plot_density(adm, 
             geom_density_args = list("fill"="blue", 
                                      "alpha"=0.6)) # distribution all predictors in the data frame
 
```

# Removing Extreme values 
Histogram and boxplots of the admission vector indicates a normal distribution for all the features. It is a recommended practice to examine the dataset for outliers. Therefore, a Inter quantile range (IQR) methodology was used to identify the "proposed outliers". First, the Q1 and Q3 quantile are identified, then the IRQ was calculated as teh difference between the Q3 and Q1. The range of values that exist below the IQR*1.5 or above IQR*1.5 were eliminated for this project. From the results only two rows were identified as potential outliers. Considering the low occurrence of these values, the dataset is being used as such with no removal of outliers. 

```{r}

any(is.na(adm)) # Checking for any missing values


IQR.outliers <- function(x) {
  if(any(is.na(x)))
    stop("x is missing values")
  if(!is.numeric(x))
    stop("x is not numeric")
  Q3<-quantile(x,0.75)
  Q1<-quantile(x,0.25)
  IQR<-(Q3-Q1)
  left<- (Q1-(1.5*IQR))
  print(left)

  right<- (Q3+(1.5*IQR))
    print(right)
  c(x[x <left],x[x>right])
}



outliers=IQR.outliers(adm$Chance.of.Admit)



```


# Data Exploration
## Check for correlations 
The dataset is examined for correlations among the different attributes. There seems to a be strong correlations (>50%) between all of the features, such as GRE. Score, TOEFL. Score, University. Rating, SOP, LOR, CGPA and Research. The boxplot on the important feature reveal a linear relationship with these features. This is an interesting trend, because many of these characteristics have confounding effects or colinearity that exist with them. For instance, a person scoring high in GRE has high probability of scoring high in TOEFL and potentially wrote a worthy statemnent of purpose. Therefore, it is essential to examinte partial correlation coefficients of these attributes on the admisssion chances.

```{r}
# Converting the data into matrix format for conduction correlation analysis
data.matrix(adm)->adm_mat 
# plotting the hrent matrix results
plot_correlation(adm_mat) 
# plotting the correlation strength through size of squares.
corrplot(cor(adm_mat), method = "square") 
```

## Visualizing the relationship 
This step further explores the relationship by visualizing the spread of the attributes and presenting the relationship between combination of attributes in influencing the admission rates. I explore the impacts of TOEFL. Score, GRE.Score and CGPA on Admission grouped by University Rating. The trend is linear and there is strong evidence that these is positively related to the admission rates and the requirements vary with Universities.


```{r}
adm%>% 
  ggplot(aes(x=TOEFL.Score,y=Chance.of.Admit, fill=factor(University.Rating))) +
  geom_boxplot() +theme_bw()+
  ggtitle("Effects of University Rating and TOEFL scores on admission")

adm%>% 
  ggplot(aes(x=GRE.Score,
             y=Chance.of.Admit, fill=factor(University.Rating))) +
  geom_boxplot() +theme_bw()+
  ggtitle("Effects of University Rating and GRE scores on admission")

adm%>% 
  ggplot(aes(x=CGPA,y=Chance.of.Admit, fill=factor(University.Rating))) +
  geom_boxplot() +theme_bw()+
  ggtitle("Effects of University Rating and CGPA scores on admission")



```


## Partial correlation coefficient
Beyond the correlation coefficients, the partial correlations reveal the influence of invidual attribute to our dependent varaible of interest. Furthermore, partial correlation ensures that the confounding effects of variables are eliminated. This analysis show that the SOP and University.Rating had a minor influence when partial correlation values are considered. Based on these findings SOP, University.Rating will be cleansed from our datasets before our modeling efforts.
```{r}
partials=pcor(adm_mat) # Conducting partial correlation analysis
print("Partial Correlations for the Dependent Variable: Rent")
Estimates=data.frame(partials$estimate[,7:8])
P.values=data.frame(partials$p.value[, 7:8])
# printing the results
kable((Estimates), format = "markdown", digits=2, 
      caption="Partial correlations  of the input dataset attributes") 

kable((P.values), format = "markdown", digits=2, 
      caption="Probability values  of the input dataset attributes") 


```
 




# Data Preparation for Modeling

##Data Cleansing
Based on the partial correlation coefficient analysis, the SOP and the University Rating features are removed from the dataset.
```{r}
adm%>%dplyr::select(-SOP, -University.Rating)->admfea # data cleansed after removing SOP
```



## Splitting data into training and validation datasets.
The data is split into two datasets. One for training and validation. The training dataset will be used for model development and the validation dataset will only be used for validation of the model as a final step. Twenty percent of the cleansed data was chosen as the validation dataset at random (318) and the rest (82) was saved as the training dataset. The attributes selected were GRE.Score, TOEFL.Score, University.Rating, LOR, CGPA and Research 

```{r}
test_indices=createDataPartition(admfea$Chance.of.Admit, 
                                 times=1, 
                                 p=0.5, # portion of data split into test
                                 list=F)
admfea[-test_indices,]->traindf # dataset reserved for training
admfea[test_indices,]->valdf # dataset held for validation
```


# Approach and Model Development

From the data types, boxplots and intial data exploration, it is evident that this is a regression problem. Accordingly, regression based modeling solutions will be explored for model development. Initially, a general linear model will be built using all of the features in the datasets. Following this a feature reduction step will be performed for the linear models using a Stepwise regression. A backward and foward propagated stepwise regression will be performed and the model that exhibits the lowest AIC score will be selected. The AIC refers to the Akaike Information Criteria that defines the performance of the model chosen through a penalization procedure.


```{r warning=F}

# cl=makePSOCKcluster(detectCores())
# registerDoParallel(cl)
# #Create control function for training with 10 folds
# #and keep 3 folds for training. search method is grid.
# 
# control <- trainControl(method='repeatedcv',
#                         number=10,
#                         repeats=3,
#                         search='grid')
# 
# tunegrid <- expand.grid(predFixed = c(1:5), minNode=1:3)
# rf_gridsearch <- train(Chance.of.Admit ~ .,
#                        data = trainset,
#                        method = 'Rborist',
#                        metric = c("RMSE"),
#                       tuneGrid = tunegrid)
# print(rf_gridsearch)
# stopCluster(cl)
```



## Linear Model
```{r}
mod.lm=lm(Chance.of.Admit~., data=traindf)
pred.lm=predict(mod.lm, newdata=valdf)
RMSE(pred.lm, valdf$Chance.of.Admit)

stepAIC(mod.lm, direction="both")


mod.lm.step=lm(Chance.of.Admit~GRE.Score+
                 TOEFL.Score+LOR+CGPA, data=traindf)
summary(mod.lm.step)

```




## Machine Learning Models
```{r}
knitr::opts_chunk$set(cache=T)
 
set.seed(1)
 
cl=makePSOCKcluster(detectCores()-1)
registerDoParallel(cl)

my.con=trainControl(method="cv", number=3,
                    savePredictions = "final", allowParallel = T)
models=caretList(Chance.of.Admit~., data=traindf,
trainControl=my.con, 
methodList = c("Rborist",  
               "knn", 
               "glmnet",
               "xgbLinear",
               "brnn", 
               "ridge"), 
continue_on_fail = T)
models$xgbLinear
models$knn
models$Rborist
models$glmnet
models$brnn
stopCluster(cl)
varImp(models$Rborist)
varImp(models$glmnet)


```


## Model with Reduced Features
```{r}
# traindf%>%dplyr::select(-Research, -SOP)->traindf_red
# cl=makePSOCKcluster(detectCores()-1)
# registerDoParallel(cl)
# models=caretList(Chance.of.Admit~., data=traindf_red,
# trainControl=my.con, 
# methodList = c("Rborist",  
#                "knn", 
#                "glmnet",
#                "xgbLinear",
#                "brnn"), 
# continue_on_fail = T)
# models$xgbLinear
# models$knn
# models$Rborist
# models$glmnet
# models$brnn
# varImp(models$Rborist)
# varImp(models$glmnet)
```



## Feature Reduction 
```{r}
set.seed(1)
cl=makePSOCKcluster(detectCores()-1)
registerDoParallel(cl)
 
ctrl=rfeControl(functions = rfFuncs,
           method = "cv",
           number = 2,
           verbose = F)
subsets=c(1:6)
lmProfile=rfe(traindf[,-6], traindf[,6], sizes=subsets, rfeControl=ctrl)
lmProfile
plot(lmProfile)
```













```{r}
 cl=makePSOCKcluster(detectCores()-1)
 registerDoParallel(cl)
 resamples<-resamples(models)
 dotplot(resamples, metric="RMSE")

```
# Results
```{r}
cl=makePSOCKcluster(detectCores())
registerDoParallel(cl)
ens=caretEnsemble(models, metric="RMSE", trControl=my.con)
summary(ens)
plot(ens)


```


#Validation

In this step, the model are evaluated for their performance. The models are used to predict the admission probabilities of the students with the validation dataset which was reserved from participating in the model developent process. The actual values of the admission rates were compared to the predicted values from various models. Both RMSE an the R2 values were evaluated. 


```{r}
#Prediction from Linear model 
pred.lm.step=predict(mod.lm.step, newdata = valdf) 

#Predicted from Rborist 

 predicted.Rborist=predict(models$Rborist, newdata=valdf)
 
#Prediction from Ensemble of the models
 predicted.ens=predict(ens, newdata=valdf)
 
 
 data.frame(Rborist=RMSE(predicted.Rborist, valdf$Chance.of.Admit), 
            Ensemble=RMSE(predicted.ens, valdf$Chance.of.Admit),
            Linear=RMSE(pred.lm.step, valdf$Chance.of.Admit))
 
 data.frame(Rborist=cor(predicted.Rborist, valdf$Chance.of.Admit), 
            Ensemble=cor(predicted.ens, valdf$Chance.of.Admit),
            Linear=cor(pred.lm.step, valdf$Chance.of.Admit))
 
 
```


# Conclusion

Comparison was made between a linear regression model and a ensemble technique with machine learning algorithms for their abilities to predict the admission probability of applicants to US graduate schools. The applicant characteristics such as GRE.Score, TOEFL.Score, CGPA, LOR and SOP were positively correlated with the admission probabilities. Both linear regression and an ensemble of maching learning algorithms both predicted the outcomes with great accuracy (RME =0.065 and R2 of 0.88). For this given problem, either of the approaches will work. Nevertheless, owing to the simplicy of linear model, for practical purposes, the linear model approach is favored.

 
 
